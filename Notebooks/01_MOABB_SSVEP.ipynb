{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOABB Dataset example\n",
    "\n",
    "Import the motor imagery (MI) trials from MOABB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "## Import libraries\n",
    "import mne\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.decoding import CSP\n",
    "from mne.decoding import PSDEstimator\n",
    "from moabb.datasets import BNCI2015004\n",
    "from moabb.paradigms import MotorImagery \n",
    "import matplotlib.collections as collections\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "from Functions import artifact_removal_tools as art\n",
    "from Functions import eeg_preprocessing\n",
    "from Functions import eeg_quality_index\n",
    "from Functions import art_pipeline\n",
    "from moabb.evaluations import WithinSessionEvaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MI data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "subjects = [1]    # List of subjects [n]\n",
    "\n",
    "# Import dataset\n",
    "dataset = BNCI2015004()\n",
    "dataset.subject_list = subjects\n",
    "\n",
    "# Select session from dataset\n",
    "sessions = dataset.get_data(subjects=subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select MI paradigm for classes (n=5): Word, Subtaction, Navigation, RightHand, and Feet\n",
    "fc = [0.1, 100] # Cut-off frequencies [Hz]\n",
    "# fc = [8, 30] # Cut-off frequencies [Hz]\n",
    "chans = ['FC3', 'FCz', 'FC4',\n",
    "        'C3', 'Cz', 'C4',\n",
    "        'CP3', 'CPz', 'CP4']    # List of str channels to use\n",
    "tmax = 6    # Time to end epoch [sec]\n",
    "# labels = ['right_hand', 'feet', 'navigation', 'subtraction', 'word_ass']    # List of str of desired events\n",
    "labels = ['right_hand', 'feet']    # List of str of desired events\n",
    "paradigm = MotorImagery(n_classes=len(labels), events=labels, fmin=fc[0], fmax=fc[1], channels=chans, tmax=tmax)\n",
    "\n",
    "[x, y, metadata] = paradigm.get_data(dataset=dataset, subjects=subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipelines\n",
    "\n",
    "Create scikit-learn pipelines for the raw data, and the data processed with the artifact removal tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_pipeline = make_pipeline(CSP(n_components=8), LDA())\n",
    "# ART_pipeline = make_pipeline(art_pipeline.ART(srate=256), CSP(n_components=8), LDA())  # Sample rate obtained from documentation\n",
    "# ART_pipeline = make_pipeline(CSP(n_components=8), LDA())  # Sample rate obtained from documentation\n",
    "\n",
    "srate = 256\n",
    "mu_band = [7.5, 12.5]\n",
    "raw_pipeline = make_pipeline(PSDEstimator(float(srate), fmin=mu_band[0], fmax=mu_band[1], verbose=False),\n",
    "                            SVC())\n",
    "ART_pipeline = make_pipeline(PSDEstimator(float(srate), fmin=mu_band[0], fmax=mu_band[1], verbose=False),\n",
    "                            SVC())\n",
    "\n",
    "# raw_pipeline = make_pipeline(LDA())\n",
    "# ART_pipeline = make_pipeline(art_pipeline.ART(srate=256), CSP(n_components=8), LDA())  # Sample rate obtained from documentation\n",
    "# ART_pipeline = make_pipeline(LDA())  # Sample rate obtained from documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using multitaper spectrum estimation with 7 DPSS windows\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danie\\Documents\\Projects\\artifact_removal_tool_validation\\Notebooks\\01_MOABB_SSVEP.ipynb Cell 8'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/Documents/Projects/artifact_removal_tool_validation/Notebooks/01_MOABB_SSVEP.ipynb#ch0000017?line=0'>1</a>\u001b[0m [x_train, x_test, y_train, y_test] \u001b[39m=\u001b[39m train_test_split(x, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.4\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, stratify\u001b[39m=\u001b[39my)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/danie/Documents/Projects/artifact_removal_tool_validation/Notebooks/01_MOABB_SSVEP.ipynb#ch0000017?line=2'>3</a>\u001b[0m raw_pipeline\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/Documents/Projects/artifact_removal_tool_validation/Notebooks/01_MOABB_SSVEP.ipynb#ch0000017?line=3'>4</a>\u001b[0m score \u001b[39m=\u001b[39m raw_pipeline\u001b[39m.\u001b[39mscore(x_test, y_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/Documents/Projects/artifact_removal_tool_validation/Notebooks/01_MOABB_SSVEP.ipynb#ch0000017?line=4'>5</a>\u001b[0m raw_predict \u001b[39m=\u001b[39m raw_pipeline\u001b[39m.\u001b[39mpredict(x_test)\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\bci_art\\lib\\site-packages\\sklearn\\pipeline.py:394\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    393\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 394\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    396\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\bci_art\\lib\\site-packages\\sklearn\\svm\\_base.py:190\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    188\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    191\u001b[0m         X,\n\u001b[0;32m    192\u001b[0m         y,\n\u001b[0;32m    193\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[0;32m    194\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    195\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    196\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    197\u001b[0m     )\n\u001b[0;32m    199\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    201\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[0;32m    202\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[0;32m    203\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\bci_art\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\bci_art\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 964\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    965\u001b[0m     X,\n\u001b[0;32m    966\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    967\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m    968\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    969\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m    970\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    971\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    972\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m    973\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m    974\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m    975\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m    976\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    977\u001b[0m )\n\u001b[0;32m    979\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\bci_art\\lib\\site-packages\\sklearn\\utils\\validation.py:794\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    790\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to convert array of bytes/strings \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    791\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39minto decimal numbers with dtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    792\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 794\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    795\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    796\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    797\u001b[0m     )\n\u001b[0;32m    799\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    800\u001b[0m     _assert_all_finite(array, allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "[x_train, x_test, y_train, y_test] = train_test_split(x, y, test_size=0.4, random_state=30, stratify=y)\n",
    "\n",
    "raw_pipeline.fit(x_train, y_train)\n",
    "score = raw_pipeline.score(x_test, y_test)\n",
    "raw_predict = raw_pipeline.predict(x_test)\n",
    "\n",
    "print(f'Score = {score:0.4f}')\n",
    "confusion_matrix(y_test, raw_predict)\n",
    "print(f'Confusion Matrix\\n {confusion_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srate = 256\n",
    "w_length = 3*srate\n",
    "[x_art_train, _, _] = art.remove_eyeblinks_cpu(x_train, srate=srate, n_clusters=10, window_length=w_length)\n",
    "[x_art_test, _, _] = art.remove_eyeblinks_cpu(x_test, srate=srate, n_clusters=10, window_length=w_length)\n",
    "\n",
    "ART_pipeline.fit(x_art_train, y_train)\n",
    "ART_pipeline.score(x_art_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_predict = ART_pipeline.predict(x_art_test)\n",
    "\n",
    "confusion_matrix(y_test, art_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate data\n",
    "\n",
    "## Evaluate raw data\n",
    "\n",
    "Evaluate the data without using the artifact removal tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = WithinSessionEvaluation(\n",
    "    paradigm=paradigm,\n",
    "    datasets=[dataset],\n",
    "    overwrite=True,\n",
    "    hdf5_path=None,\n",
    ")\n",
    "\n",
    "raw_results = evaluation.process({\"csp+lda\": raw_pipeline})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate ART data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x_art, _, _] = art.remove_eyeblinks_cpu(x, srate=256, window_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_results = evaluation.process({\"art+csp+lda\": ART_pipeline}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train2, y_test = train_test_split(x, y, test_size=0.9, random_state=30, stratify=y)\n",
    "# From here pick x_train and y_train to do ART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x[0:33,:,:]\n",
    "a.info['sfreq']\n",
    "srate = int(a.info['sfreq'])\n",
    "[x_art,_,_] = art.remove_eyeblinks_cpu(z, srate, window_length=3*srate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 15\n",
    "chan = 3\n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(z[epoch,chan,:])\n",
    "ax[1].plot(x_art[epoch,chan,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b =a.info['ch_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(art.remove_eyeblinks_cpu(srate, window=3*srate), CSP(n_components=30), LDA())\n",
    "\n",
    "evaluation = WithinSessionEvaluation(\n",
    "    paradigm=paradigm,\n",
    "    datasets=[dataset],\n",
    "    overwrite=True,\n",
    "    hdf5_path=None,\n",
    ")\n",
    "\n",
    "results2 = evaluation.process({\"csp+lda\": pipeline})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb2adf991b30cb540516a6e97af5670ff3f67d0a5a80c19c9be25f6eee52dcc1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('bci_art')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
